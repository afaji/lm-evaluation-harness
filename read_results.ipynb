{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Get list of TSV files in folder\n",
    "tsv_files = glob.glob(\"./eval_res/*.txt\")\n",
    "\n",
    "# print(tsv_files)\n",
    "all_res = defaultdict(dict)\n",
    "task_metric = defaultdict(list)\n",
    "\n",
    "all_res_std = defaultdict(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in tsv_files:\n",
    "    results = json.load(open(file))\n",
    "    model = results[\"config\"][\"model_args\"].replace(\"pretrained=\", \"\").split(\"/\")[-1]\n",
    "    if \"wrapper\" in file:\n",
    "        model = model + \"-wrapper\"\n",
    "    task = list(results[\"results\"].keys())[0]\n",
    "    \n",
    "    res_keys = sorted(list(results[\"results\"][task].keys()), key=lambda x: len(x))\n",
    "    metric = 0.0\n",
    "    metric_std = 0.0\n",
    "    metric_name = None\n",
    "    \n",
    "    for key in res_keys:\n",
    "        if \"std\" not in key:\n",
    "            metric = results[\"results\"][task][key] * 100\n",
    "            metric_name = key\n",
    "        else:\n",
    "            metric_std = results[\"results\"][task][key] * 100\n",
    "            \n",
    "    if task == \"record\":\n",
    "        metric = results[\"results\"][task][\"f1\"] * 100\n",
    "        metric_std = results[\"results\"][task][\"f1_stderr\"] * 100\n",
    "        metric_name = \"f1\"\n",
    "    \n",
    "    all_res[model][task] = metric\n",
    "    all_res_std[model][task] = metric_std\n",
    "    task_metric[task].append(metric_name) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['flan-t5-small-distil-v2', 'Cerebras-GPT-256M-distil-v1',\n",
       "       't5-large-distil-v1', 't5-base', 'gpt2', 't5-base-distil-v2',\n",
       "       'Cerebras-GPT-111M', 'gpt2-xl', 'Cerebras-GPT-1.3B-distil-v1-wrapper',\n",
       "       'Cerebras-GPT-590M-distil-v1-wrapper', 'gpt2-large', 'flan-t5-base',\n",
       "       't5-large', 'Cerebras-GPT-111M-distil-v1-wrapper', 't5-small',\n",
       "       'flan-t5-base-distil-v4', 'gpt-neo-125m', 'gpt2-xl-distil-v1-wrapper',\n",
       "       'Cerebras-GPT-256M', 'gpt2-distil-v1-wrapper',\n",
       "       'Cerebras-GPT-590M-distil-v1', 'flan-t5-large', 'flan-t5-small',\n",
       "       'Cerebras-GPT-256M-distil-v1-wrapper', 'gpt2-large-distil-v1-wrapper',\n",
       "       'Cerebras-GPT-1.3B', 'Cerebras-GPT-590M', 'gpt-neo-1.3B',\n",
       "       'flan-t5-large-distil-v1', 'gpt-neo-125m-distil-v1-wrapper'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(all_res_std)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_columns = [\"t5-small\", 'flan-t5-small', 'flan-t5-small-distil-v2', \n",
    "                't5-base', 'flan-t5-base', 'flan-t5-base-distil-v4',\n",
    "                'Cerebras-GPT-256M', 'Cerebras-GPT-256M-distil-v1', 'Cerebras-GPT-256M-distil-v1-wrapper',\n",
    "                'Cerebras-GPT-590M', 'Cerebras-GPT-590M-distil-v1', 'Cerebras-GPT-590M-distil-v1-wrapper',\n",
    "                'Cerebras-GPT-111M', 'Cerebras-GPT-111M-distil-v1-wrapper',\n",
    "                'gpt-neo-125m','gpt-neo-125m-distil-v1-wrapper',\n",
    "                'gpt2', 'gpt2-distil-v1-wrapper',\n",
    "                'gpt2-large', 'gpt2-large-distil-v1-wrapper',\n",
    "                'gpt2-xl', 'gpt2-xl-distil-v1-wrapper', \n",
    "                't5-large', 'flan-t5-large', 'flan-t5-large-distil-v1', \n",
    "                'Cerebras-GPT-1.3B', 'gpt-neo-1.3B', 't5-large-distil-v1',\n",
    "                't5-base-distil-v2',\n",
    "                'Cerebras-GPT-1.3B-distil-v1-wrapper',\n",
    "                ]\n",
    "\n",
    "task_sort = [\"openbookqa\", \"sciq\", \"race\", \"arc_challenge\", \"piqa\",\n",
    "            \n",
    "            \"record\", \n",
    "            \n",
    "            \"webqs\", #\"triviaqa\",\n",
    "            \n",
    "            \"sst\", \n",
    "            \n",
    "            \"mrpc\", #\"qqp\", \n",
    "            \n",
    "            \"cb\", \"rte\", \"mnli\",  \"mnli_mismatched\",\n",
    "            \n",
    "            \"wsc\", \"wsc273\", \"winogrande\",\n",
    "            \n",
    "            \"wic\", \n",
    "            \n",
    "            \"copa\", \"hellaswag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in list(df.columns) if x not in sorted_columns ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_res)\n",
    "\n",
    "df = df[sorted_columns]\n",
    "\n",
    "sorted_df = df.loc[task_sort]\n",
    "\n",
    "metrics = [task_metric[x][0] for x in task_sort]\n",
    "\n",
    "sorted_df.insert(loc=0, column=\"metric\", value=metrics)\n",
    "sorted_df.to_csv(\"metric_res.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_res_std)\n",
    "\n",
    "df = df[sorted_columns]\n",
    "\n",
    "sorted_df = df.loc[task_sort]\n",
    "\n",
    "metrics = [task_metric[x][0] for x in task_sort]\n",
    "\n",
    "sorted_df.insert(loc=0, column=\"metric\", value=metrics)\n",
    "sorted_df.to_csv(\"metric_std.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>t5-small</th>\n",
       "      <th>flan-t5-small</th>\n",
       "      <th>flan-t5-small-distil-v2</th>\n",
       "      <th>t5-base</th>\n",
       "      <th>flan-t5-base</th>\n",
       "      <th>flan-t5-base-distil-v4</th>\n",
       "      <th>Cerebras-GPT-256M</th>\n",
       "      <th>Cerebras-GPT-256M-distil-v1</th>\n",
       "      <th>Cerebras-GPT-256M-distil-v1-wrapper</th>\n",
       "      <th>...</th>\n",
       "      <th>gpt2-xl</th>\n",
       "      <th>gpt2-xl-distil-v1-wrapper</th>\n",
       "      <th>t5-large</th>\n",
       "      <th>flan-t5-large</th>\n",
       "      <th>Cerebras-GPT-1.3B</th>\n",
       "      <th>gpt-neo-1.3B</th>\n",
       "      <th>t5-large-distil-v1</th>\n",
       "      <th>t5-base-distil-v2</th>\n",
       "      <th>Cerebras-GPT-1.3B-distil-v1-wrapper</th>\n",
       "      <th>flan-t5-large-distil-v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>openbookqa</th>\n",
       "      <td>acc_norm</td>\n",
       "      <td>30.200000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>32.800000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>39.800000</td>\n",
       "      <td>32.800000</td>\n",
       "      <td>31.200000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.600000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sciq</th>\n",
       "      <td>acc_norm</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>79.400000</td>\n",
       "      <td>71.700000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>86.500000</td>\n",
       "      <td>65.700000</td>\n",
       "      <td>70.400000</td>\n",
       "      <td>68.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.100000</td>\n",
       "      <td>80.400000</td>\n",
       "      <td>82.400000</td>\n",
       "      <td>93.800000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>77.100000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>82.900000</td>\n",
       "      <td>79.400000</td>\n",
       "      <td>86.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>acc</td>\n",
       "      <td>26.411483</td>\n",
       "      <td>29.665072</td>\n",
       "      <td>28.899522</td>\n",
       "      <td>31.100478</td>\n",
       "      <td>35.885167</td>\n",
       "      <td>33.971292</td>\n",
       "      <td>27.464115</td>\n",
       "      <td>29.186603</td>\n",
       "      <td>27.081340</td>\n",
       "      <td>...</td>\n",
       "      <td>33.110048</td>\n",
       "      <td>39.138756</td>\n",
       "      <td>31.483254</td>\n",
       "      <td>40.861244</td>\n",
       "      <td>30.334928</td>\n",
       "      <td>34.066986</td>\n",
       "      <td>32.631579</td>\n",
       "      <td>32.631579</td>\n",
       "      <td>32.918660</td>\n",
       "      <td>32.822967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arc_challenge</th>\n",
       "      <td>acc_norm</td>\n",
       "      <td>22.696246</td>\n",
       "      <td>22.269625</td>\n",
       "      <td>23.976109</td>\n",
       "      <td>24.402730</td>\n",
       "      <td>25.085324</td>\n",
       "      <td>27.815700</td>\n",
       "      <td>21.928328</td>\n",
       "      <td>24.232082</td>\n",
       "      <td>26.109215</td>\n",
       "      <td>...</td>\n",
       "      <td>28.498294</td>\n",
       "      <td>35.750853</td>\n",
       "      <td>25.426621</td>\n",
       "      <td>30.716724</td>\n",
       "      <td>25.255973</td>\n",
       "      <td>25.853242</td>\n",
       "      <td>29.010239</td>\n",
       "      <td>26.450512</td>\n",
       "      <td>30.290102</td>\n",
       "      <td>31.825939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piqa</th>\n",
       "      <td>acc_norm</td>\n",
       "      <td>55.331882</td>\n",
       "      <td>61.860718</td>\n",
       "      <td>61.860718</td>\n",
       "      <td>55.712731</td>\n",
       "      <td>66.974973</td>\n",
       "      <td>65.778020</td>\n",
       "      <td>61.425462</td>\n",
       "      <td>61.479869</td>\n",
       "      <td>61.425462</td>\n",
       "      <td>...</td>\n",
       "      <td>70.511425</td>\n",
       "      <td>71.327530</td>\n",
       "      <td>55.930359</td>\n",
       "      <td>72.198041</td>\n",
       "      <td>66.757345</td>\n",
       "      <td>71.055495</td>\n",
       "      <td>67.192601</td>\n",
       "      <td>63.982590</td>\n",
       "      <td>66.866159</td>\n",
       "      <td>70.565832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record</th>\n",
       "      <td>f1</td>\n",
       "      <td>53.401905</td>\n",
       "      <td>57.705238</td>\n",
       "      <td>53.752524</td>\n",
       "      <td>64.551667</td>\n",
       "      <td>68.232905</td>\n",
       "      <td>61.513333</td>\n",
       "      <td>61.206714</td>\n",
       "      <td>59.407524</td>\n",
       "      <td>58.568333</td>\n",
       "      <td>...</td>\n",
       "      <td>84.449238</td>\n",
       "      <td>78.495952</td>\n",
       "      <td>73.068524</td>\n",
       "      <td>76.698143</td>\n",
       "      <td>75.027952</td>\n",
       "      <td>81.377476</td>\n",
       "      <td>68.723429</td>\n",
       "      <td>59.097095</td>\n",
       "      <td>66.331797</td>\n",
       "      <td>70.401762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webqs</th>\n",
       "      <td>acc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.874016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.289370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.525591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.574803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.588583</td>\n",
       "      <td>0.935039</td>\n",
       "      <td>1.673228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst</th>\n",
       "      <td>acc</td>\n",
       "      <td>70.986239</td>\n",
       "      <td>87.270642</td>\n",
       "      <td>85.665138</td>\n",
       "      <td>57.339450</td>\n",
       "      <td>92.316514</td>\n",
       "      <td>91.399083</td>\n",
       "      <td>49.770642</td>\n",
       "      <td>58.256881</td>\n",
       "      <td>76.949541</td>\n",
       "      <td>...</td>\n",
       "      <td>49.082569</td>\n",
       "      <td>93.463303</td>\n",
       "      <td>50.229358</td>\n",
       "      <td>94.036697</td>\n",
       "      <td>51.261468</td>\n",
       "      <td>65.711009</td>\n",
       "      <td>90.252294</td>\n",
       "      <td>91.169725</td>\n",
       "      <td>90.252294</td>\n",
       "      <td>93.119266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrpc</th>\n",
       "      <td>acc</td>\n",
       "      <td>48.039216</td>\n",
       "      <td>63.235294</td>\n",
       "      <td>58.578431</td>\n",
       "      <td>31.617647</td>\n",
       "      <td>71.323529</td>\n",
       "      <td>74.754902</td>\n",
       "      <td>68.382353</td>\n",
       "      <td>68.382353</td>\n",
       "      <td>68.382353</td>\n",
       "      <td>...</td>\n",
       "      <td>63.235294</td>\n",
       "      <td>75.980392</td>\n",
       "      <td>34.313725</td>\n",
       "      <td>82.598039</td>\n",
       "      <td>68.382353</td>\n",
       "      <td>68.382353</td>\n",
       "      <td>71.078431</td>\n",
       "      <td>73.529412</td>\n",
       "      <td>71.323529</td>\n",
       "      <td>77.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb</th>\n",
       "      <td>acc</td>\n",
       "      <td>41.071429</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>58.928571</td>\n",
       "      <td>44.642857</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>39.285714</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>82.142857</td>\n",
       "      <td>30.357143</td>\n",
       "      <td>44.642857</td>\n",
       "      <td>51.785714</td>\n",
       "      <td>30.357143</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>66.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rte</th>\n",
       "      <td>acc</td>\n",
       "      <td>53.429603</td>\n",
       "      <td>60.288809</td>\n",
       "      <td>56.317690</td>\n",
       "      <td>61.371841</td>\n",
       "      <td>78.700361</td>\n",
       "      <td>67.870036</td>\n",
       "      <td>52.346570</td>\n",
       "      <td>49.097473</td>\n",
       "      <td>55.595668</td>\n",
       "      <td>...</td>\n",
       "      <td>52.346570</td>\n",
       "      <td>67.870036</td>\n",
       "      <td>79.783394</td>\n",
       "      <td>87.364621</td>\n",
       "      <td>53.068592</td>\n",
       "      <td>60.288809</td>\n",
       "      <td>57.039711</td>\n",
       "      <td>71.480144</td>\n",
       "      <td>65.703971</td>\n",
       "      <td>64.981949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnli</th>\n",
       "      <td>acc</td>\n",
       "      <td>35.445746</td>\n",
       "      <td>42.424860</td>\n",
       "      <td>53.204279</td>\n",
       "      <td>56.729496</td>\n",
       "      <td>66.744778</td>\n",
       "      <td>67.967397</td>\n",
       "      <td>35.150280</td>\n",
       "      <td>37.890983</td>\n",
       "      <td>38.991340</td>\n",
       "      <td>...</td>\n",
       "      <td>36.535914</td>\n",
       "      <td>67.539480</td>\n",
       "      <td>61.293938</td>\n",
       "      <td>72.379012</td>\n",
       "      <td>35.150280</td>\n",
       "      <td>35.843097</td>\n",
       "      <td>54.722364</td>\n",
       "      <td>54.712175</td>\n",
       "      <td>47.356088</td>\n",
       "      <td>61.365257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnli_mismatched</th>\n",
       "      <td>acc</td>\n",
       "      <td>35.191212</td>\n",
       "      <td>42.544752</td>\n",
       "      <td>53.224166</td>\n",
       "      <td>57.119609</td>\n",
       "      <td>66.924329</td>\n",
       "      <td>67.829536</td>\n",
       "      <td>35.058991</td>\n",
       "      <td>38.984947</td>\n",
       "      <td>40.347844</td>\n",
       "      <td>...</td>\n",
       "      <td>36.991456</td>\n",
       "      <td>69.324654</td>\n",
       "      <td>63.069569</td>\n",
       "      <td>72.019935</td>\n",
       "      <td>35.353946</td>\n",
       "      <td>36.167616</td>\n",
       "      <td>55.797396</td>\n",
       "      <td>55.522783</td>\n",
       "      <td>49.186330</td>\n",
       "      <td>61.004882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc</th>\n",
       "      <td>acc</td>\n",
       "      <td>50.961538</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>47.115385</td>\n",
       "      <td>63.461538</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>58.653846</td>\n",
       "      <td>36.538462</td>\n",
       "      <td>39.423077</td>\n",
       "      <td>36.538462</td>\n",
       "      <td>...</td>\n",
       "      <td>49.038462</td>\n",
       "      <td>54.807692</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>36.538462</td>\n",
       "      <td>36.538462</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>50.961538</td>\n",
       "      <td>45.192308</td>\n",
       "      <td>63.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc273</th>\n",
       "      <td>acc</td>\n",
       "      <td>50.915751</td>\n",
       "      <td>53.113553</td>\n",
       "      <td>54.578755</td>\n",
       "      <td>53.846154</td>\n",
       "      <td>57.509158</td>\n",
       "      <td>58.241758</td>\n",
       "      <td>54.578755</td>\n",
       "      <td>54.212454</td>\n",
       "      <td>49.450549</td>\n",
       "      <td>...</td>\n",
       "      <td>73.260073</td>\n",
       "      <td>69.597070</td>\n",
       "      <td>60.439560</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>62.271062</td>\n",
       "      <td>75.091575</td>\n",
       "      <td>58.974359</td>\n",
       "      <td>54.212454</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>64.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winogrande</th>\n",
       "      <td>acc</td>\n",
       "      <td>48.934491</td>\n",
       "      <td>50.039463</td>\n",
       "      <td>50.118390</td>\n",
       "      <td>50.355170</td>\n",
       "      <td>54.222573</td>\n",
       "      <td>53.670087</td>\n",
       "      <td>51.302289</td>\n",
       "      <td>51.065509</td>\n",
       "      <td>52.012628</td>\n",
       "      <td>...</td>\n",
       "      <td>58.326756</td>\n",
       "      <td>56.037885</td>\n",
       "      <td>55.169692</td>\n",
       "      <td>59.905288</td>\n",
       "      <td>51.933702</td>\n",
       "      <td>54.932912</td>\n",
       "      <td>54.853986</td>\n",
       "      <td>51.933702</td>\n",
       "      <td>51.775848</td>\n",
       "      <td>55.958958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wic</th>\n",
       "      <td>acc</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>51.253918</td>\n",
       "      <td>50.783699</td>\n",
       "      <td>52.037618</td>\n",
       "      <td>52.664577</td>\n",
       "      <td>60.501567</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>51.097179</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.843260</td>\n",
       "      <td>52.351097</td>\n",
       "      <td>49.373041</td>\n",
       "      <td>64.733542</td>\n",
       "      <td>50.156740</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.470219</td>\n",
       "      <td>55.956113</td>\n",
       "      <td>50.156740</td>\n",
       "      <td>63.793103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>copa</th>\n",
       "      <td>acc</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hellaswag</th>\n",
       "      <td>acc_norm</td>\n",
       "      <td>26.817367</td>\n",
       "      <td>29.147580</td>\n",
       "      <td>28.579964</td>\n",
       "      <td>31.049592</td>\n",
       "      <td>36.436965</td>\n",
       "      <td>34.106752</td>\n",
       "      <td>28.599881</td>\n",
       "      <td>28.540131</td>\n",
       "      <td>29.306911</td>\n",
       "      <td>...</td>\n",
       "      <td>50.886278</td>\n",
       "      <td>48.287194</td>\n",
       "      <td>38.866760</td>\n",
       "      <td>48.705437</td>\n",
       "      <td>38.388767</td>\n",
       "      <td>48.934475</td>\n",
       "      <td>40.599482</td>\n",
       "      <td>32.045409</td>\n",
       "      <td>38.747262</td>\n",
       "      <td>43.666600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   metric   t5-small  flan-t5-small  flan-t5-small-distil-v2  \\\n",
       "openbookqa       acc_norm  30.200000      27.000000                30.000000   \n",
       "sciq             acc_norm  58.000000      89.000000                79.400000   \n",
       "race                  acc  26.411483      29.665072                28.899522   \n",
       "arc_challenge    acc_norm  22.696246      22.269625                23.976109   \n",
       "piqa             acc_norm  55.331882      61.860718                61.860718   \n",
       "record                 f1  53.401905      57.705238                53.752524   \n",
       "webqs                 acc   0.000000       7.874016                 0.000000   \n",
       "sst                   acc  70.986239      87.270642                85.665138   \n",
       "mrpc                  acc  48.039216      63.235294                58.578431   \n",
       "cb                    acc  41.071429      42.857143                50.000000   \n",
       "rte                   acc  53.429603      60.288809                56.317690   \n",
       "mnli                  acc  35.445746      42.424860                53.204279   \n",
       "mnli_mismatched       acc  35.191212      42.544752                53.224166   \n",
       "wsc                   acc  50.961538      38.461538                47.115385   \n",
       "wsc273                acc  50.915751      53.113553                54.578755   \n",
       "winogrande            acc  48.934491      50.039463                50.118390   \n",
       "wic                   acc  50.000000      51.253918                50.783699   \n",
       "copa                  acc  50.000000      61.000000                63.000000   \n",
       "hellaswag        acc_norm  26.817367      29.147580                28.579964   \n",
       "\n",
       "                   t5-base  flan-t5-base  flan-t5-base-distil-v4  \\\n",
       "openbookqa       34.800000     28.800000               32.800000   \n",
       "sciq             71.700000     93.000000               86.500000   \n",
       "race             31.100478     35.885167               33.971292   \n",
       "arc_challenge    24.402730     25.085324               27.815700   \n",
       "piqa             55.712731     66.974973               65.778020   \n",
       "record           64.551667     68.232905               61.513333   \n",
       "webqs             0.000000     16.289370                0.000000   \n",
       "sst              57.339450     92.316514               91.399083   \n",
       "mrpc             31.617647     71.323529               74.754902   \n",
       "cb               64.285714     82.142857               58.928571   \n",
       "rte              61.371841     78.700361               67.870036   \n",
       "mnli             56.729496     66.744778               67.967397   \n",
       "mnli_mismatched  57.119609     66.924329               67.829536   \n",
       "wsc              63.461538     50.000000               58.653846   \n",
       "wsc273           53.846154     57.509158               58.241758   \n",
       "winogrande       50.355170     54.222573               53.670087   \n",
       "wic              52.037618     52.664577               60.501567   \n",
       "copa             60.000000     66.000000               70.000000   \n",
       "hellaswag        31.049592     36.436965               34.106752   \n",
       "\n",
       "                 Cerebras-GPT-256M  Cerebras-GPT-256M-distil-v1  \\\n",
       "openbookqa               25.400000                    28.600000   \n",
       "sciq                     65.700000                    70.400000   \n",
       "race                     27.464115                    29.186603   \n",
       "arc_challenge            21.928328                    24.232082   \n",
       "piqa                     61.425462                    61.479869   \n",
       "record                   61.206714                    59.407524   \n",
       "webqs                     0.000000                     1.525591   \n",
       "sst                      49.770642                    58.256881   \n",
       "mrpc                     68.382353                    68.382353   \n",
       "cb                       44.642857                     7.142857   \n",
       "rte                      52.346570                    49.097473   \n",
       "mnli                     35.150280                    37.890983   \n",
       "mnli_mismatched          35.058991                    38.984947   \n",
       "wsc                      36.538462                    39.423077   \n",
       "wsc273                   54.578755                    54.212454   \n",
       "winogrande               51.302289                    51.065509   \n",
       "wic                      50.000000                    51.097179   \n",
       "copa                     64.000000                    60.000000   \n",
       "hellaswag                28.599881                    28.540131   \n",
       "\n",
       "                 Cerebras-GPT-256M-distil-v1-wrapper  ...    gpt2-xl  \\\n",
       "openbookqa                                 30.600000  ...  32.000000   \n",
       "sciq                                       68.800000  ...  76.100000   \n",
       "race                                       27.081340  ...  33.110048   \n",
       "arc_challenge                              26.109215  ...  28.498294   \n",
       "piqa                                       61.425462  ...  70.511425   \n",
       "record                                     58.568333  ...  84.449238   \n",
       "webqs                                       0.000000  ...   1.574803   \n",
       "sst                                        76.949541  ...  49.082569   \n",
       "mrpc                                       68.382353  ...  63.235294   \n",
       "cb                                          7.142857  ...  39.285714   \n",
       "rte                                        55.595668  ...  52.346570   \n",
       "mnli                                       38.991340  ...  36.535914   \n",
       "mnli_mismatched                            40.347844  ...  36.991456   \n",
       "wsc                                        36.538462  ...  49.038462   \n",
       "wsc273                                     49.450549  ...  73.260073   \n",
       "winogrande                                 52.012628  ...  58.326756   \n",
       "wic                                        50.000000  ...  49.843260   \n",
       "copa                                       61.000000  ...  73.000000   \n",
       "hellaswag                                  29.306911  ...  50.886278   \n",
       "\n",
       "                 gpt2-xl-distil-v1-wrapper   t5-large  flan-t5-large  \\\n",
       "openbookqa                       39.800000  32.800000      31.200000   \n",
       "sciq                             80.400000  82.400000      93.800000   \n",
       "race                             39.138756  31.483254      40.861244   \n",
       "arc_challenge                    35.750853  25.426621      30.716724   \n",
       "piqa                             71.327530  55.930359      72.198041   \n",
       "record                           78.495952  73.068524      76.698143   \n",
       "webqs                             0.000000   0.000000      22.588583   \n",
       "sst                              93.463303  50.229358      94.036697   \n",
       "mrpc                             75.980392  34.313725      82.598039   \n",
       "cb                               64.285714  75.000000      82.142857   \n",
       "rte                              67.870036  79.783394      87.364621   \n",
       "mnli                             67.539480  61.293938      72.379012   \n",
       "mnli_mismatched                  69.324654  63.069569      72.019935   \n",
       "wsc                              54.807692  61.538462      76.923077   \n",
       "wsc273                           69.597070  60.439560      66.666667   \n",
       "winogrande                       56.037885  55.169692      59.905288   \n",
       "wic                              52.351097  49.373041      64.733542   \n",
       "copa                             76.000000  66.000000      71.000000   \n",
       "hellaswag                        48.287194  38.866760      48.705437   \n",
       "\n",
       "                 Cerebras-GPT-1.3B  gpt-neo-1.3B  t5-large-distil-v1  \\\n",
       "openbookqa               29.000000     33.600000           36.000000   \n",
       "sciq                     73.000000     77.100000           84.500000   \n",
       "race                     30.334928     34.066986           32.631579   \n",
       "arc_challenge            25.255973     25.853242           29.010239   \n",
       "piqa                     66.757345     71.055495           67.192601   \n",
       "record                   75.027952     81.377476           68.723429   \n",
       "webqs                     0.935039      1.673228            0.000000   \n",
       "sst                      51.261468     65.711009           90.252294   \n",
       "mrpc                     68.382353     68.382353           71.078431   \n",
       "cb                       30.357143     44.642857           51.785714   \n",
       "rte                      53.068592     60.288809           57.039711   \n",
       "mnli                     35.150280     35.843097           54.722364   \n",
       "mnli_mismatched          35.353946     36.167616           55.797396   \n",
       "wsc                      36.538462     36.538462           46.153846   \n",
       "wsc273                   62.271062     75.091575           58.974359   \n",
       "winogrande               51.933702     54.932912           54.853986   \n",
       "wic                      50.156740     50.000000           50.470219   \n",
       "copa                     70.000000     69.000000           69.000000   \n",
       "hellaswag                38.388767     48.934475           40.599482   \n",
       "\n",
       "                 t5-base-distil-v2  Cerebras-GPT-1.3B-distil-v1-wrapper  \\\n",
       "openbookqa               32.000000                            34.000000   \n",
       "sciq                     82.900000                            79.400000   \n",
       "race                     32.631579                            32.918660   \n",
       "arc_challenge            26.450512                            30.290102   \n",
       "piqa                     63.982590                            66.866159   \n",
       "record                   59.097095                            66.331797   \n",
       "webqs                     0.000000                             0.000000   \n",
       "sst                      91.169725                            90.252294   \n",
       "mrpc                     73.529412                            71.323529   \n",
       "cb                       30.357143                            28.571429   \n",
       "rte                      71.480144                            65.703971   \n",
       "mnli                     54.712175                            47.356088   \n",
       "mnli_mismatched          55.522783                            49.186330   \n",
       "wsc                      50.961538                            45.192308   \n",
       "wsc273                   54.212454                            57.142857   \n",
       "winogrande               51.933702                            51.775848   \n",
       "wic                      55.956113                            50.156740   \n",
       "copa                     65.000000                            67.000000   \n",
       "hellaswag                32.045409                            38.747262   \n",
       "\n",
       "                 flan-t5-large-distil-v1  \n",
       "openbookqa                     34.000000  \n",
       "sciq                           86.700000  \n",
       "race                           32.822967  \n",
       "arc_challenge                  31.825939  \n",
       "piqa                           70.565832  \n",
       "record                         70.401762  \n",
       "webqs                           0.000000  \n",
       "sst                            93.119266  \n",
       "mrpc                           77.941176  \n",
       "cb                             66.071429  \n",
       "rte                            64.981949  \n",
       "mnli                           61.365257  \n",
       "mnli_mismatched                61.004882  \n",
       "wsc                            63.461538  \n",
       "wsc273                         64.102564  \n",
       "winogrande                     55.958958  \n",
       "wic                            63.793103  \n",
       "copa                           71.000000  \n",
       "hellaswag                      43.666600  \n",
       "\n",
       "[19 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
